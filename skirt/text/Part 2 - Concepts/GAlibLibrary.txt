/**

\page GAlib The Genetic Algorithms library

\section GAlibIntro Introduction

\note The GAlib library was written by Matthew Wall (Massachusetts Institute of Technology)
      and can be downloaded at http://lancet.mit.edu/ga/GAlib.html

The GAlib code included with SKIRT was reorganized and adjusted to comply with modern compiler standards,
eliminating compiler warnings and errors, and making the code more transparent for the human reader.
Also, some unused classes were omitted.
The original GAlib code was written in the nineties, before the C++98 standard was established.
In those days the behavior of class and function templates was not yet well defined and things tended to vary
between compilers, which forced Matthew Wall to introduce a large number of compile-time conditionals. Since there
now \em is a well-established standard, we removed much of this complexity in the version included with SKIRT.
Other than these changes, the code is Matthew Wall's and all the credit goes to him.

\note The remaining text in this chapter is copied from the GAlib documentation, with minor modifications.

\section GAlibFeat Features

This section lists the major features of the GAlib library.

\subsection GAlibFeatAlgo Algorithms, Parameters, and Statistics

- Genetic algorithm parameters can be configured from file, command-line, and/or code.
- Overlapping (steady-state GA) and non-overlapping (simple GA) populations are supported.
  You can also specify the amount of overlap (% replacement).
  The distribution includes examples of other derived genetic algorithms
  such as a genetic algorithm with sub-populations and another that uses deterministic crowding.
- New genetic algorithms can be quickly tested by deriving from the base genetic algorithm classes in the library.
  In many cases you need only overide one virtual function.
- Built-in termination methods include convergence and number-of-generations.
  The termination method can be customized for any existing genetic algorithm class or for new classes you derive.
- Speciation can be done with either DeJong-style crowding (using a replacement strategy)
  or Goldberg-style sharing (using fitness scaling).
- Elitism is optional for non-overlapping genetic algorithms.
- Built-in replacement strategies (for overlapping populations) include replace parent, replace random, replace worst.
  The replacement operator can be customized.
- Built-in selection methods include rank, roulette wheel, tournament, stochastic remainder sampling,
  stochastic uniform sampling, and deterministic sampling. The selection operator can be customized.
- "on-line" and "off-line" statistics are recorded as well as max, min, mean, standard deviation, and diversity.
  You can specify which statistics should be recorded and how often they should be flushed to file.

\subsection GAlibFeatGeno Genomes and Operators

- Chromosomes can be built from any C++ data type. You can use the types built-in to the library
  (bit-string, array, list, tree) or derive a chromosome based on your own objects.
- Built-in chromosome types include real number arrays, list, tree, 1D, 2D, and 3D arrays, 1D, 2D, and 3D binary
  string. The binary strings, strings, and arrays can be variable length. The lists and trees can contain any object
  in their nodes. The array can contain any object in each element.
- All chromosome initialization, mutation, crossover, and comparison methods can be customized.
- Built-in initialization operators include uniform random, order-based random, allele-based random, and
  initialize-to-zero.
- Built-in mutation operators include random flip, random swap, Gaussian, destructive, swap subtree, swap node.
- Built-in crossover operators include arithmetic, blend, partial match, ordered, cycle, single point, two point,
  even, odd, uniform, node- and subtree-single point.
- Dominance and Diploidy are not explicitly built in to the library, but any of the genome classes in the library
  can easily be extended to become diploid chromosomes.

\subsection GAlibFeatObj Objective function

- Objective functions can be population- or individual-based.
- If the built-in genomes adequately represent your problem,
  a user-specified objective function is the only problem-specific code that must be written.


\section GAlibOver Overview

This section outlines the contents of the library and presents some of the design philosophy behind the
implementation. When you use the library you will work primarily with two classes: a genome and a genetic algorithm.
Each genome instance represents a single solution to your problem. The genetic algorithm object defines how the
evolution should take place. The genetic algorithm uses an objective function (defined by you) to determine how 'fit'
each genome is for survival. It uses the genome operators (built into the genome) and selection/replacement strategies
(built into the genetic algorithm) to generate new individuals.

There are three things you must do to solve a problem using a genetic algorithm:
 - Define a representation;
 - Define the genetic operators;
 - Define the objective function.

GAlib helps you with the first two items by providing many examples and pieces from which you can build your
representation and operators. In many cases you can use the built-in representations and operators with little or no
modification. The objective function is completely up to you. Once you have a representation, operators, and objective
measure, you can apply any genetic algorithm to find better solutions to your problem. When you use a genetic algorithm
to solve an optimization problem, you must be able to represent a single solution to your problem in a single data
structure. The genetic algorithm will create a population of solutions based on a sample data structure that you
provide. The genetic algorithm then operates on the population to evolve the best solution. In GAlib, the sample data
structure is called a GAGenome (some people refer to it as a chromosome). The library contains four types of genomes:
GAListGenome, GATreeGenome, GAArrayGenome, and GABinaryStringGenome. These classes are derived from the base GAGenome
class and a data structure class as indicated by their names. For example, the GAListGenome is derived from the GAList
class as well as the GAGenome class. Use a data structure that works with your problem definition. For example, if you
are trying to optimize a function that depends on 5 real numbers, then use as your genome a 1-dimensional array of
floats with 5 elements.

There are many different types of genetic algorithms. GAlib includes three basic types: 'simple', 'steady-state', and
'incremental'. These algorithms differ in the way that they create new individuals and replace old individuals during
the course of an evolution.

GAlib provides two primary mechanisms for extending the capabilities of built-in objects. First of all (and most
preferred, from a C++ point of view), you can derive your own classes and define new member functions. If you need to
make only minor adjustments to the behavior of a GAlib class, in most cases you can define a single function and tell
the existing GAlib class to use it instead of the default.

Genetic algorithms, when properly implemented, are capable of both exploration (broad search) and exploitation (local
search) of the search space. The type of behavior you'll get depends on how the operators work and on the 'shape' of
the search space.

\subsection GAlibOverAlgo The Genetic Algorithm

The genetic algorithm object determines which individuals should survive, which should reproduce, and which should die.
It also records statistics and decides how long the evolution should continue. Typically a genetic algorithm has no
obvious stopping criterion. You must tell the algorithm when to stop. Often the number-of-generations is used as a
stopping measure, but you can use goodness-of-best-solution, convergence-of-population, or any problem-specific
criterion if you prefer.

The library contains four flavors of genetic algorithms. The first is the standard 'simple genetic algorithm' described
by Goldberg in his book. This algorithm uses non-overlapping populations and optional elitism. Each generation the
algorithm creates an entirely new population of individuals. The second is a 'steady-state genetic algorithm' that uses
overlapping populations. In this variation, you can specify how much of the population should be replaced in each
generation. The third variation is the 'incremental genetic algorithm', in which each generation consists of only one
or two children. The incremental genetic algorithms allow custom replacement methods to define how the new generation
should be integrated into the population. So, for example, a newly generated child could replace its parent, replace a
random individual in the population, or replace an individual that is most like it. The fourth type is the 'deme'
genetic algorithm. This algorithm evolves multiple populations in parallel using a steady-state algorithm. Each
generation the algorithm migrates some of the individuals from each population to one of the other populations.

In addition to the basic built-in types, GAlib defines the components you'll need to derive your own genetic algorithm
classes. The examples include a few of these derivations including (1) a genetic algorithm that uses multiple
populations and 'migration' between populations on multiple CPUs, and (2) a genetic algorithm that does 'deterministic
crowding' to maintain different species of individuals during the evolution.

The base genetic algorithm class contains operators and data common to most flavors of genetic algorithms. When you
derive your own genetic algorithm you can use these member data and functions to keep track of statistics and monitor
performance.

The genetic algorithm contains the statistics, replacement strategy, and parameters for running the algorithm. the
population object, a container for genomes, also contains some statistics as well as selection and scaling operators. A
typical genetic algorithm will run forever. The library has built in functions for specifying when the algorithm should
terminate. These include terminate-upon-generation, in which you specify a certain number of generations for which the
algorithm should run, and terminate-upon-convergence, in which you specify a value to which the best-of-generation
score should converge. You can customize the termination function to use your own stopping criterion.

The number of function evaluations is a good way to compare different genetic algorithms with various other search
methods. The GAlib genetic algorithms keep track of both the number of genome evaluations and population evaluations.

\subsection GAlibOverRep Defining a Representation

Use a data structure that is appropriate for your problem. If you are optimizing a function of real numbers, use real
numbers in your genome. If a solution to your problem can be represented with some imaginary numbers and some integer
values, define a genome with these characteristics.

Defining an appropriate representation is part of the art of using genetic algorithms (and at this point, it is still
an art, not a science). Use a representation that is minimal but completely expressive. Your representation should be
able to represent any solution to your problem, but if at all possible you should design it so that it cannot represent
infeasible solutions to your problem. Remember that if the genome can represent infeasible solutions then the objective
function must be designed to give partial credit to infeasibles.

The representation should not contain information beyond that needed to represent a solution to the problem. Although
there may be merit in using a representation that contains 'extra' genetic material, unless properly implemented (in
concert with the objective function and in full consideration of the type and characteristics of the search space),
this tends to increase the size of the search space and thus hinder the performance of the genetic algorithm.

The number of possible representations is endless. You may choose a purely numeric representation such as an array of
real numbers. These could be implemented as real numbers, or, in the Goldberg-style of a string of bits that map to
real numbers (beware that using real numbers directly far out-performs the binary-to-decimal representation for most
problems, especially when you use reasonable crossover operators). Your problem may depend on a sequence of items, in
which case an order-based representation (either list or array) may be more appropriate. In many of these cases, you
must choose operators that maintain the integrity of the sequence; crossover must generate reordered lists without
duplicating any element in the list. Other problems lend themselves to a tree structure. Here you may want to represent
solutions explicitly as trees and perform the genetic operations on the trees directly. Alternatively, many people
encode trees into an array or parsable string, then operate on the string. Some problems include a mix of continuous
and discrete elements, in which case you may need to create a new structure to hold the mix of information. In these
cases you must define genetic operators that respect the structure of the solution. For example, a solution with both
integer and floating parts might use a crossover that crosses integer parts with integer parts and floating parts with
floating parts, but never mixes floating parts with integer parts.

Whichever representation you choose, be sure to pick operators that are appropriate for your representation.

\subsection GAlibOverOper The Genome Operators

Each genome has three primary operators: initialization, mutation, and crossover. With these operators you can bias an
initial population, define a mutation or crossover specific to your problem's representation, or evolve parts of the
genetic algorithm as your population evolves. GAlib comes with these operators pre-defined for each genome type, but
you can customize any of them.

The initialization operator determines how the genome is initialized. It is called when you initialize a population or
the genetic algorithm. This operator does not actually create new genomes, rather it 'stuffs' the genomes with the
primordial genetic material from which all solutions will evolve. The population object has its own initialization
operator. By default this simply calls the initialization operators of the genomes in the population, but you can
customize it to do whatever you want.

The mutation operator defines the procedure for mutating each genome. Mutation means different things for different
data types. For example, a typical mutator for a binary string genome flips the bits in the string with a given
probability. A typical mutator for a tree, on the other hand, would swap subtrees with a given probability. In general,
you should define a mutation that can do both exploration and exploitation; mutation should be able to introduce new
genetic material as well as modify existing material. You may want to define multiple types of mutation for a single
problem.

The crossover operator defines the procedure for generating a child from two parent genomes. Like the mutation
operator, crossover is specific to the data type. Unlike mutation, however, crossover involves multiple genomes. In
GAlib, each genome 'knows' its preferred method of mating (the default crossover method) but it is incapable of
performing crossover itself. Each genetic algorithm 'knows' how to get the default crossover method from its genomes
then use that method to peform the mating. With this model it is possible to derive new genetic algorithm classes that
use mating methods other than the defaults defined for a genome.

Each of these methods can be customized so that it is specific not only to the data type, but also to the problem type.
This is one way you can put some problem-specific 'intelligence' into the genetic algorithm (I won't go into a
discussion about whether or not this is a good thing to do...)

In addition to the three primary operators, each genome must also contain an objective function and may also contain a
comparator. The objective function is used to evaluate the genome. The comparator (often referred to as a 'distance
function') is used to determine how different one genome is from another. Every genetic algorithm requires that an
objective function is defined - this is how the genetic algorithm determines which individuals are better than others.
Some genetic algorithms require a comparator.

The library has some basic data types built in, but if you already have an array or list object, for example, then you
can quickly build a genome from it by multiply inheriting from your object and the genome object. You can then use this
new object directly in the GAlib genetic algorithm objects.

In general, a genetic algorithm does not need to know about the contents of the data structures on which it is
operating. The library reflects this generality. You can mix and match genome types with genetic algorithms. The
genetic algorithm knows how to clone genomes in order to create populations, initialize genomes to start a run, cross
genomes to generate children, and mutate genomes. All of these operations are performed via the genome member
functions.

\subsection GAlibOverPop The Population Object

The population object is a container for genomes. Each population object has its own initializer (the default simply
calls the initializer for each individual in the population) and evaluator (the default simply calls the evaluator for
each individual in the population). It also keeps track of the best, average, deviation, etc for the population.
Diversity can be recorded as well, but since diversity calculations often require a great deal of additional
compuation, the default is to not record diversity.

The selection method is also defined in the population object. This method is used by the genetic algorithms to choose
which individuals should mate.

Each population object has a scaling scheme object associated with it. The scaling scheme object converts the objective
score of each genome to a fitness score that the genetic algorithm uses for selection. It also caches fitness
information for use later on by the selection schemes.

\subsection GAlibOverObj Objective Functions and Fitness Scaling

Genetic algorithms are often more attractive than gradient search methods because they do not require compilicated
differential equations or a smooth search space. The genetic algorithm needs only a single measure of how good a single
individual is compared to the other individuals. The objective function provides this measure; given a single solution
to a problem, how good is it?

It is important to note the distinction between fitness and objective scores. The objective score is the value returned
by your objective function; it is the raw performance evaluation of a genome. The fitness score, on the other hand, is
a possibly-transformed rating used by the genetic algorithm to determine the fitness of individuals for mating. The
fitness score is typically obtained by a linear scaling of the raw objective scores (but you can define any mapping you
want, or no transformation at all). For example, if you use linear scaling then the fitness scores are derived from the
objective scores using the fitness proportional scaling technique described in Goldberg's book. The genetic algorithm
uses the fitness scores, not the objective scores, to do selection.

You can evaluate the individuals in a population using an individual-based evaluation function (which you define), or a
population-based evaluator (also which you define). If you use an individual-based objective, then the function is
assigned to each genome. A population-based objective function can make use of individual objective functions, or it
can set the individual scores itself.

*/
