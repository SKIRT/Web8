/**

\page UserFitSkirtHPC Running FitSKIRT on the VSC infrastructure

This section presents a brief example of how to use <tt>FitSKIRT</tt> on the infrastructure of the Flemish
Supercomputer Center (<a href="https://vscentrum.be/en">Vlaams Supercomputer Centrum</a> or VSC). To begin with, it is
important to build the \c SKIRT project with MPI (see the \ref InstallationGuide), so that multi-processing is enabled.
In a nutshell:

\verbatim
$ module load CMake
$ cd SKIRT/git
$ ./configSKIRT.sh BUILD_FIT_SKIRT=ON BUILD_WITH_MPI=ON
$ ./makeSKIRT.sh
\endverbatim

Here is an example job script that could be used to run <tt>FitSKIRT</tt>, once it has been successfully built:

\verbatim
#!/bin/sh
#
#PBS -N name
#PBS -o output.txt
#PBS -e error.txt
#PBS -l walltime=40:00:00
#PBS -l nodes=4:ppn=16
#PBS -m be

# load the MPI implementation used when building FitSKIRT
module load iimpi vsc-mympirun

# use the scratch space as a working directory
cd $VSC_SCRATCH/run_fitskirt/myfit

# the -h 16 option runs 16 processes per node
mympirun -h 16 $HOME/SKIRT/release/FitSKIRT/main/fitskirt -o $VSC_SCRATCH/run_fitskirt/myfit/run1 myfit.fski
\endverbatim

Load the relevant modules to provide the MPI implementation used when building the \c SKIRT project. Specify absolute
paths to the appropriate directories and run \c FitSKIRT using \c mympirun, a local customized version of the standard
\c mpirun command. It is best to leave the -s and -t options at their default values of 1, and use the \c mympirun -h
option to specify a number of processes per node that matches the number of cores. This way each SKIRT simulation runs
on a single thread in a single process. This turns out to be the optimal parallelization strategy when \c FitSKIRT is
running in multi-processing mode.

The optimal values of the job scheduling settings (specified with the \#PBS options at the start of the job script) are
more difficult to determine. Preferably, the requested wall time is set to a value that is not much longer than the
expected running time, because the job scheduling algorithm favors shorter jobs. However this running time is hard to
predict, unless you have performed a number of similar fitting schemes on the same computer infrastructure.

Another important choice to be made is the number of requested nodes. As indicated above, it is best to match the
number of processes per node to the number of available cores per node. <tt>FitSKIRT</tt> can utilize at most one
parallel process for each individual in the genetic algorithm population that needs to be evaluated. For the first
generation, all individuals in the population must be evaluated. For subsequent generations, however, the individuals
that are inherited from the previous generation do not need to be evaluated. This number is guided by the crossover
probability, and is thus unfortunately not deterministic.

Denoting the number of cores per node as \f$N_\text{core}\f$, the genetic algorithm population size as
\f$N_\text{pop}\f$, and the crossover probability as \f$p_\text{cross}\f$, we can say that:
 - It makes no sense to allocate more than \f$\text{ceil}(N_\text{pop}/N_\text{core})\f$ nodes to the job.
 - During all but the first generation, it would seem to be more resource efficient to allocate only
   \f$\text{ceil}((1-p_\text{cross})N_\text{pop}/N_\text{core})\f$ nodes.
 - However, due to the probabilistic nature of the number of individuals to be evaluated, the latter strategy could
   backfire. If the number of processes is 'just' insufficient to handle all individuals in parallel, the remaining few
   individuals are handled in a subsequent, second batch, during which all of the other processes are idle.

There are generally two ways to handle these issues:
 - Allocate a "large" number of nodes as indicated in the above analysis, and live with the resulting inefficiencies.
 - Allocate a "small" number of nodes, say 3 or 4 times less than indicated in the above analysis, substantially
   improving the load balancing between processes, while at the same time increasing the wall time needed for the job.

The latter strategy might be the best option as long as the running time stays under the strict wall time limit imposed
by the VSC scheduling system.

*/
