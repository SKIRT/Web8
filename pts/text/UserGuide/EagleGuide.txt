/**

\page UserEagle Post-processing EAGLE galaxies with PTS and SKIRT

\section EagleIntro Introduction

The EAGLE project (<a href="http://adsabs.harvard.edu/abs/2015MNRAS.446..521S">Schaye et al. 2015</a>) consists of a
suite of SPH simulations that follow the formation of galaxies and large-scale structure in cosmologically
representative volumes. EAGLE employs sub-grid recipes for radiative cooling, star formation, stellar mass loss, and
feedback from stars and acccreting black holes. The reference simulation numerically resolves thousands of galaxies in
a 100 Mpc box that also contains groups and clusters.

The EAGLE simulation output is available through the <a href="http://icc.dur.ac.uk/Eagle/database.php">EAGLE data web
interface</a>. Integrated EAGLE galaxy properties can be obtained through SQL queries, and full particle data can be
downloaded for further processing. The particle data are stored in a (large) set of HDF5 data files organized in \em
snapshots, where each snapshot represents the state of the universe at a particular time (or equivalently, redshift).

SKIRT is a Monte Carlo dust radiative transfer code developed by the Astronomical Observatory at the Ghent University.
It is ideally suited to post-process the results of the EAGLE simulation to calculate observable properties
(images and SEDs) from UV to submm wavelengths, properly taking into account the effects of dust.

The Python toolkit for SKIRT (PTS) offers functionality related to working with SKIRT, including tools to
import data, visualize results, and run test cases. This page provides an overview of the portion of PTS that
is dedicated to post-processing EAGLE galaxies with SKIRT. Specific functionality offered in this area includes:
  - extracting relevant information from the EAGLE output in a format that can be used in SKIRT
  - scheduling large numbers of SKIRT simulations and managing/retrieving the results
  - processing and visualizing the SKIRT results in meaningful ways


\section EagleBasic The basics

\subsection EagleBasicDirs Directory organization

For an overview of the PTS directory structure at large, refer to \ref DevDirs.
For information on how to use PTS command line scripts, refer to \ref UserUseDo.

The source code for the EAGLE-dedicated classes and functions is grouped into the \c pts/eagle directory. This code can
freely use the functionality offered by the classes and functions in any of the other \c pts subdirectories.

The EAGLE-dedicated command line scripts reside in the \c pts/do/eagle directory. Assuming you have added the proper
commands to your shell login script (see \ref InstallMacSetUp_path ore \ref InstallUbuntuSetUp_path), you can execute
the EAGLE script called \c show.py by entering "pts eagle/show".

The directory paths for input and output files used by the PTS EAGLE tools are defined in \c pts/eagle/config.py and
can be easily adjusted to the local environment.

\subsection EagleBasicRuns SKIRT runs

To help manage many thousands of SKIRT simulations and their results, the PTS EAGLE tools rely on a simple SQL database
implemented from within Python. Each record in the database represents a single SKIRT simulation called a "SKIRT run".
The record contains some basic information on the EAGLE galaxy being simulated, on the SKIRT parameters being used, and
on the current status of the simulation. Refer to the \c pts.eagle.database package for a description of the fields
maintained for each record in this SKIRT-runs database.

Each record in the SKIRT-runs database, and thus each SKIRT simulation run, is automatically assigned a unique integer
identifier, called a "run-id". One consequence is that, when a particular EAGLE galaxy is post-processed multiple times,
perhaps with a different SKIRT parameter file, each simulation run is assigned a different run-id. The run-id also
determines the location of the SKIRT input/output files related to this run
inside a subdirectory of the results directory configured in the \c pts.eagle.config
script.

Specifically, the files for a SKIRT run are placed in a two-level subdirectory hierarchy with names based on the
run-id. The bottom-level directories are named according to the pattern "r-nnnn-nnn" where the literal \em r stands for
"run" and the \em n stand for the consecutive digits of the run-id. The dashes are included for readability. The
top-level directories are named according to the pattern "g-nnnn" where the literal \em r stands for "group" and the
\em n stand for the most significant digits of the run-id. Each top-level directory contains the 1000 bottom-level
directories with corresponding most-significant digits.

Inside each run directory the data is organized as follows:
  - the SKIRT parameter file (ski file) is placed immediately inside the run directory
  - input data for SKIRT is placed in the "in" subdirectory
  - output data from SKIRT is placed in the "out" subdirectory
  - data derived from the SKIRT results (e.g. for visualization) are placed in the "vis" subdirectory

\subsection EagleBasicFlow Workflow

The workflow implemented by the EAGLE PTS tools and tracked in the SKIRT-runs database includes a number of \em stages,
i.e. workflow steps that need to be accomplished. The most important stages are:
  - insert: add the record to the SKIRT-runs database, properly completing all of its fields.
  - extract: extract the particle data for the galaxy to be simulated from the appropriate EAGLE snapshot.
  - simulate: perform the SKIRT simulation for the galaxy.
  - observe: calculate the desired observables such as broadband magnitudes or images from the SKIRT results.

These operations are performed in separate stages because the resource requirements differ substantially. For example,
extraction uses only a single thread/core, while a SKIRT simulation can (and should) be heavily parallelized. Also,
this setup allows adjusting and re-running, say, the observe stage without having to rerun the SKIRT simulation.

Within each workflow stage, the database also tracks the \em status of the operation, which is one of the following:
  - scheduled: the operation is ready to proceed (this assumes the previous stages have been completed successfully).
  - running: the operation is currently being performed.
  - failed: the operation failed.
  - succeeded: the operation has been completed successfully.

This workflow is supported by the various scripts in the \c pts/do/eagle folder. The most important ones are :
  - \c show: list a selection of SKIRT-run records.
  - \c status: list a summary of the workflow status for a set of SKIRT-run records.
  - \c update: update a given field in a selection of SKIRT-run records (for manual tweaks or corrections).
  - \c insert: insert SKIRT-run records for EAGLE galaxies selected from the public EAGLE database.
  - \c advance: advance SKIRT-runs with "succeeded" status to the next workflow stage.
  - \c perform: interactively perform a workflow stage for scheduled SKIRT-runs (not for stages that need parallel execution)
  - \c submit: submit batch jobs to perform a workflow stage for scheduled SKIRT-runs
  - \c build: build one of several visualization options for a given set of SKIRT-runs (assumes the observe stage has completed).
  - \c collect: collect results for a set of SKIRT-runs into a single file (assumes the observe stage has completed).

The following section presents the usage of these scripts as part of a typical workflow. For more specific details,
refer to the documentation of each script.


\section EagleFlow The EAGLE PTS workflow

\subsection EagleFlowConfig Configuration

Before using the EAGLE PTS tools, you need to:
  - download or otherwise ensure access to the relevant EAGLE snapshot data files (see \ref EagleIntro).
  - install SKIRT and PTS (see the respective installation guides).
  - optionally create and checkout a new git branch so that your changes are not in the master branch
    (this is not important if you do not plan to contribute code to the PTS repository).
  - update the path definitions in \c pts/eagle/config.py to values appropriate for your operating environment
    (see pts.eagle.config).

\subsection EagleFlowStart Getting started

Setting up the EAGLE-SKIRT workflow for the first time on a new computer involves:
  - editing the \em config.py source file in the \c eagle directory to include the path definitions
    and other settings appropriate for the platform (see eagle.config);
  - creating the SKIRT-runs database from an interactive Python session by invoking the
    eagle.database.Database.createtable() function:

\verbatim
import eagle.database
db = eagle.database.Database()
db.createtable()
db.close()
\endverbatim

When requirements and functionalities evolve, it is possible to add extra fields to the database records
throught the eagle.database.Database.addfield() function, or perform other database maintenance tasks by executing
"raw" SQL statements through the eagle.database.Database.execute() function.
See <a href="http://www.sqlite.org/lang.html">www.sqlite.org</a> for information on the SQL dialect supported by
the SQLite library version 3.7.3.

Before making these kind of changes
to the database, always make a backup through the eagle.database.backup() function.

\subsection EagleFlowCat Snapshots and catalogs

After configuring a new default EAGLE snapshot (see eagle.config) for the first time, you need to construct a catalog
for the galaxies in the snapshot. To do this, run the \em eagle_catalog script:

\verbatim
$ pts catalog
Opening the snapshot...
Directory: /Users/pcamps/EAGLE/Snapshots/L0012N0188REF
...
Do you want to build the catalog for Ref12 at redshift 0? (y/n) yes
Building catalog...
...
done.
\endverbatim

\subsection EagleFlowSki SKIRT parameter files

You need to provide one or more ski files (SKIRT parameter files) in the directory specified in eagle.config
to serve as a template for controlling the actual SKIRT simulations. Attributes that vary with the
galaxy being simulated will be automatically replaced in the ski file before the simulation is started.
These include for example the input filenames for star and gas particles, the extent of the dust grid and the
instruments, and the number of photon packages.

\subsection EagleFlowPop Populating the database

The first step in a typical workflow is to populate the SKIRT-runs database with records describing the SKIRT
simulations you'd like to perform. This process involves selecting a number of galaxies (identified by halo group and
subgroup numbers) in the EAGLE snaphot for a particular redshift, and identifying the ski file template that will
be used to control the actual simulation.

The \c eagle_insert command-line script offers a (currently quite primitive) implementation of this workflow step.
The script expects exactly five command-line arguments specifying respectively:

 - a label that will identify the set of inserted records in the database
 - the name of the ski file template (without extension) to be used for these runs
 - a minimum number of particles for stars and gas (same minimum for each particle type)
 - a minimum stellar mass (in solar mass units)
 - a maximum stellar mass (in solar mass units)

The script shows the records that will be inserted into the database, and offers the user a chance
to accept or reject the additions. For example:

\verbatim
$ pts insert MyTest oligo 20000 1e9 1e10
Executing: MyTest oligo 20000 1e9 1e10
Opening the snaphot...
Box size:  100.0 Mpc
Redshift:  0.000
Expansion: 100.0%
Files:     256
Star particles: 170,562,276
Gas particles:  909,733,923
['runid', 'username', 'label', 'runstatus', ... 'groupnr', 'subgroupnr', ..., 'skitemplate']
(10, 'pcamps', 'MyTest', 'inserted', ..., 1110, 0, 20344, 21261, ..., 'oli')
(11, 'pcamps', 'MyTest', 'inserted', ..., 1192, 0, 20116, 20449, ..., 'oli')
...
(16, 'pcamps', 'MyTest', 'inserted', ..., 1495, 0, 20363, 20591, ..., 'oli')
--> Would you like to commit these 7 new records to the database? [y/n]: y
New records were committed to the database
$
\endverbatim

The label field (here set to 'MyTest') serves to identify related records so that they can be managed as a group.

The \c eagle_show command-line script lists selected records in the database, using a general SQL query.
For example the following command would list the records just inserted:

\verbatim
$ pts show "label='MyTest'"
...
\endverbatim

The \c eagle_update command-line script similarly allows updating the value of a particular field in selected records.
Just as with insertion of new record, the update script shows the records that will be updated, and offers the user
a chance to accept or reject the modifications.
For example the following command would update the value of the 'skitemplate' field for records in the 'MyTest'
set that have not yet been scheduled for execution:

\verbatim
$ pts update "label='MyTest' and runstatus='inserted'" skitemplate panchro
...
\endverbatim

\subsection EagleFlowSched Scheduling SKIRT simulations

The \c eagle_schedule command-line script schedules jobs for selected records in the SKIRT-runs database.
When invoked without command line arguments, the script schedules a job for each record that has a run-status
of 'inserted' and a username equal to the current user. After the script exits, these records will have a run-status
of 'scheduled'.

Alternatively the script accepts a single command line argument specifying the run-id for a database record.
A job will be scheduled for the specified record regardless of its original run-status, and the record's run-status
will be updated to 'scheduled'. This is handy to reschedule jobs that did not complete successfully.

If the script is executed on the Cosma cluster, it creates and submits an actual job to the queuing system to
perform the SKIRT simulation. For example:

\verbatim
$ pts sched 11
Executing: eagle_schedule 11
Submitting job for run-id 11 to queue cosma5
Job accepted for project dp004-eagle for user pcamps.
Job <660888> is submitted to queue <cosma5>.
pcamps@cosma-a:~$ bjobs -w
JOBID   USER    STAT  QUEUE   FROM_HOST  EXEC_HOST   JOB_NAME     SUBMIT_TIME
660888  pcamps  RUN   cosma5  cosma-a    m5049:...   SKIRT-run-11 Feb 15 15:01
$
\endverbatim

For more information on the queuing system refer to
<a href="http://icc.dur.ac.uk/index.php?content=Computing/Batch#section1.1">Job Scheduling on
the Durham COSMA machines</a>.

If the \c eagle_schedule script is executed on a regular computer, its asks the user to perform the job by hand.
For example:

\verbatim
$ pts sched 11
Executing: eagle_schedule 11
Please manually execute scheduled job for run-id 11
$ pts run 11
Executing: eagle_run 11
Exporting galaxy (2164,0) from 2 files...
Welcome to SKIRT v6 (...)
...
$
\endverbatim

The \c eagle_run command-line script actually executes a SKIRT simulation on an EAGLE galaxy,
according to the specifications defined in the specified SKIRT-runs database record.
It extracts the relevant particle data from the EAGLE snapshot files, adjusts the ski file template appropriately,
calls SKIRT to perform the radiative transfer simulation, and creates relevant visualizations in png or pdf files.
The script is invoked from the batch jobs created by the eagle_schedule script, and it can also be run manually.

The run-status of the specified record must be 'scheduled'; if not the script fails.
The script sets the run-status to 'running' while it is running, and it finally
updates the run-status to 'completed' or 'failed' before exiting.

\subsection EagleFlowVis Visualizing the results

The results of an EAGLE-SKIRT simulation are stored in a directory hierarchy as described in eagle.skirtrun.SkirtRun.
The root path is configured in eagle.config.

The \c eagle_run command-line script automatically produces some visualizations that pertain to each individual
simulation. For example a plot for the SED produced by each instrument, or an RGB image for the total flux.
Visualizations involving the results of multiple simulations (e.g. scaling relations) can be produced as a
separate process by specialized scripts. These scripts can use the eagle.database.Database class to select and
access SKIRT-run records in the target set or with the desired characteristics, and the
eagle.skirtrun.SkirtRun and pts.skirtsimulation.SkirtSimulation classes to access SKIRT simulation results.

*/
